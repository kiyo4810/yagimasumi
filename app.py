import streamlit as st
import requests
from bs4 import BeautifulSoup

# ã‚µã‚¤ãƒˆã®è¨­å®š
st.set_page_config(page_title="ã‚µãƒãƒ³ãƒŠå…«æœ¨ å‡ºæ¼”æƒ…å ±", page_icon="ğŸ“º")
st.title("ğŸ“º ã‚µãƒãƒ³ãƒŠå…«æœ¨çœŸæ¾„ å‡ºæ¼”æƒ…å ±")

def get_yagi_schedule():
    url = "https://bangumi.org/talents/142568"
    headers = {"User-Agent": "Mozilla/5.0"}
    
    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        
        # bangumi.org ã®ç•ªçµ„ãƒªã‚¹ãƒˆã®å¡Šã‚’ç‰¹å®š
        # æ”¾é€æ—¥ãƒ»æ™‚é–“ãƒ»ç•ªçµ„åãŒå«ã¾ã‚Œã‚‹æ (program_list_data)ã‚’å–å¾—
        items = soup.select(".program_list_data")
        
        schedule = []
        for item in items:
            # å†…éƒ¨ã®ä½™è¨ˆãªç©ºç™½ã‚’æ•´ç†ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            text = item.get_text(separator=" ").strip()
            # 1è¡Œã«ã¾ã¨ã¾ã‚Šã™ããªã„ã‚ˆã†èª¿æ•´
            clean_text = " ".join(text.split())
            if clean_text:
                schedule.append(clean_text)
        return schedule
    except Exception as e:
        return [f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"]

# ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨è¡¨ç¤º
data = get_yagi_schedule()

if data:
    st.success(f"æœ€æ–°ã®äºˆå®šãŒ {len(data)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼")
    for s in data:
        # 1ä»¶ãšã¤ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
        with st.expander(s[:40] + "...", expanded=True):
            st.write(s)
else:
    st.warning("ç¾åœ¨ã€å–å¾—ã§ãã‚‹æ–°ã—ã„å‡ºæ¼”äºˆå®šã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µã‚¤ãƒˆå´ã®æ›´æ–°ã‚’ãŠå¾…ã¡ãã ã•ã„ã€‚")

st.divider()
st.caption("ãƒ‡ãƒ¼ã‚¿å…ƒ: bangumi.org (ã‚µãƒãƒ³ãƒŠå…«æœ¨çœŸæ¾„ å‡ºæ¼”ç•ªçµ„ä¸€è¦§)")
